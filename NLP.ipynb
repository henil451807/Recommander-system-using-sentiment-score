{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c73d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\A To Z\n",
      "[nltk_data]     Infosys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\A To Z\n",
      "[nltk_data]     Infosys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fc5186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\A To Z\n",
      "[nltk_data]     Infosys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\A To Z\n",
      "[nltk_data]     Infosys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0acbe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\A To Z Infosys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87db1e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the last couple of years we’ve shared the joys and excitement of discovering fabulous content across OTT platforms with you. But there are some who are simply intimidated by the volume of content and feel more comfortable watching reruns on television. The free forty eight hours of Netflix is a great opportunity for those still wondering what to watch to dive right in.  I’ve discovered a penchant for European shows, shows coming out of Latin America, and of course what is known as K-Dramas, Chinese and Japanese shows as well. That’s me, and these are from just one of the OTT platforms that is offering us all a break from the monotony of being inside and safe from the pandemic taking so many lives.\n"
     ]
    }
   ],
   "source": [
    "text=\"Over the last couple of years we’ve shared the joys and excitement of discovering fabulous content across OTT platforms with you. But there are some who are simply intimidated by the volume of content and feel more comfortable watching reruns on television. The free forty eight hours of Netflix is a great opportunity for those still wondering what to watch to dive right in.  I’ve discovered a penchant for European shows, shows coming out of Latin America, and of course what is known as K-Dramas, Chinese and Japanese shows as well. That’s me, and these are from just one of the OTT platforms that is offering us all a break from the monotony of being inside and safe from the pandemic taking so many lives.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93632b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "b=blankline_tokenize(text)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddbd006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens=word_tokenize(text)                        #nltk.download('punket')\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80d6e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'of': 8, 'the': 6, 'and': 6, '.': 5, ',': 4, '’': 3, 'are': 3, 'is': 3, 'a': 3, 'shows': 3, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "f=FreqDist()\n",
    "for i in tokens:\n",
    "    f[i]+=1\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f33bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 8), ('the', 6), ('and', 6), ('.', 5), (',', 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw =f.most_common(5)\n",
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f6c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over==over\n",
      "the==the\n",
      "last==last\n",
      "couple==coupl\n",
      "of==of\n",
      "years==year\n",
      "we==we\n",
      "’==’\n",
      "ve==ve\n",
      "shared==share\n",
      "the==the\n",
      "joys==joy\n",
      "and==and\n",
      "excitement==excit\n",
      "of==of\n",
      "discovering==discov\n",
      "fabulous==fabul\n",
      "content==content\n",
      "across==across\n",
      "OTT==ott\n",
      "platforms==platform\n",
      "with==with\n",
      "you==you\n",
      ".==.\n",
      "But==but\n",
      "there==there\n",
      "are==are\n",
      "some==some\n",
      "who==who\n",
      "are==are\n",
      "simply==simpli\n",
      "intimidated==intimid\n",
      "by==by\n",
      "the==the\n",
      "volume==volum\n",
      "of==of\n",
      "content==content\n",
      "and==and\n",
      "feel==feel\n",
      "more==more\n",
      "comfortable==comfort\n",
      "watching==watch\n",
      "reruns==rerun\n",
      "on==on\n",
      "television==televis\n",
      ".==.\n",
      "The==the\n",
      "free==free\n",
      "forty==forti\n",
      "eight==eight\n",
      "hours==hour\n",
      "of==of\n",
      "Netflix==netflix\n",
      "is==is\n",
      "a==a\n",
      "great==great\n",
      "opportunity==opportun\n",
      "for==for\n",
      "those==those\n",
      "still==still\n",
      "wondering==wonder\n",
      "what==what\n",
      "to==to\n",
      "watch==watch\n",
      "to==to\n",
      "dive==dive\n",
      "right==right\n",
      "in==in\n",
      ".==.\n",
      "I==i\n",
      "’==’\n",
      "ve==ve\n",
      "discovered==discov\n",
      "a==a\n",
      "penchant==penchant\n",
      "for==for\n",
      "European==european\n",
      "shows==show\n",
      ",==,\n",
      "shows==show\n",
      "coming==come\n",
      "out==out\n",
      "of==of\n",
      "Latin==latin\n",
      "America==america\n",
      ",==,\n",
      "and==and\n",
      "of==of\n",
      "course==cours\n",
      "what==what\n",
      "is==is\n",
      "known==known\n",
      "as==as\n",
      "K-Dramas==k-drama\n",
      ",==,\n",
      "Chinese==chines\n",
      "and==and\n",
      "Japanese==japanes\n",
      "shows==show\n",
      "as==as\n",
      "well==well\n",
      ".==.\n",
      "That==that\n",
      "’==’\n",
      "s==s\n",
      "me==me\n",
      ",==,\n",
      "and==and\n",
      "these==these\n",
      "are==are\n",
      "from==from\n",
      "just==just\n",
      "one==one\n",
      "of==of\n",
      "the==the\n",
      "OTT==ott\n",
      "platforms==platform\n",
      "that==that\n",
      "is==is\n",
      "offering==offer\n",
      "us==us\n",
      "all==all\n",
      "a==a\n",
      "break==break\n",
      "from==from\n",
      "the==the\n",
      "monotony==monotoni\n",
      "of==of\n",
      "being==be\n",
      "inside==insid\n",
      "and==and\n",
      "safe==safe\n",
      "from==from\n",
      "the==the\n",
      "pandemic==pandem\n",
      "taking==take\n",
      "so==so\n",
      "many==mani\n",
      "lives==live\n",
      ".==.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "p=PorterStemmer()\n",
    "for i in tokens:\n",
    "    print(i+\"==\"+p.stem(i))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33f6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "l=WordNetLemmatizer()                               #need nltk.download('wordnet')\n",
    "print(l.lemmatize('couple'))                        #need nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abac3f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('last', 'JJ'),\n",
       " ('couple', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'RB'),\n",
       " ('shared', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('joys', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('excitement', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('discovering', 'VBG'),\n",
       " ('fabulous', 'JJ'),\n",
       " ('content', 'NN'),\n",
       " ('across', 'IN'),\n",
       " ('OTT', 'NNP'),\n",
       " ('platforms', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('some', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('simply', 'RB'),\n",
       " ('intimidated', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('volume', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('content', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('feel', 'VB'),\n",
       " ('more', 'RBR'),\n",
       " ('comfortable', 'JJ'),\n",
       " ('watching', 'VBG'),\n",
       " ('reruns', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('television', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('free', 'JJ'),\n",
       " ('forty', 'NN'),\n",
       " ('eight', 'CD'),\n",
       " ('hours', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Netflix', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('opportunity', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('still', 'RB'),\n",
       " ('wondering', 'VBG'),\n",
       " ('what', 'WP'),\n",
       " ('to', 'TO'),\n",
       " ('watch', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('dive', 'VB'),\n",
       " ('right', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'RB'),\n",
       " ('discovered', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('penchant', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('European', 'JJ'),\n",
       " ('shows', 'NNS'),\n",
       " (',', ','),\n",
       " ('shows', 'NNS'),\n",
       " ('coming', 'VBG'),\n",
       " ('out', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('Latin', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('of', 'IN'),\n",
       " ('course', 'NN'),\n",
       " ('what', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('known', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('K-Dramas', 'NNP'),\n",
       " (',', ','),\n",
       " ('Chinese', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Japanese', 'JJ'),\n",
       " ('shows', 'NNS'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('.', '.'),\n",
       " ('That', 'DT'),\n",
       " ('’', 'VBZ'),\n",
       " ('s', 'JJR'),\n",
       " ('me', 'PRP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('these', 'DT'),\n",
       " ('are', 'VBP'),\n",
       " ('from', 'IN'),\n",
       " ('just', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('OTT', 'NNP'),\n",
       " ('platforms', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('offering', 'VBG'),\n",
       " ('us', 'PRP'),\n",
       " ('all', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('break', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('monotony', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('inside', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('safe', 'JJ'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pandemic', 'JJ'),\n",
       " ('taking', 'VBG'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('lives', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=nltk.pos_tag(tokens)\n",
    "pos                                                     #need nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870bdf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840d4ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'austen-emma.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t='austen-emma.txt'\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec6c14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=nltk.corpus.gutenberg.words(t)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5da114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7717"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=nltk.corpus.gutenberg.sents(t)\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfeab15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino.zip', 'gutenberg', 'gutenberg.zip', 'omw-1.4.zip', 'stopwords', 'stopwords.zip', 'wordnet.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9440e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Over', 'the', 'last', 'couple', 'of', 'years'),\n",
       " ('the', 'last', 'couple', 'of', 'years', 'we'),\n",
       " ('last', 'couple', 'of', 'years', 'we', '’'),\n",
       " ('couple', 'of', 'years', 'we', '’', 've'),\n",
       " ('of', 'years', 'we', '’', 've', 'shared'),\n",
       " ('years', 'we', '’', 've', 'shared', 'the'),\n",
       " ('we', '’', 've', 'shared', 'the', 'joys'),\n",
       " ('’', 've', 'shared', 'the', 'joys', 'and'),\n",
       " ('ve', 'shared', 'the', 'joys', 'and', 'excitement'),\n",
       " ('shared', 'the', 'joys', 'and', 'excitement', 'of'),\n",
       " ('the', 'joys', 'and', 'excitement', 'of', 'discovering'),\n",
       " ('joys', 'and', 'excitement', 'of', 'discovering', 'fabulous'),\n",
       " ('and', 'excitement', 'of', 'discovering', 'fabulous', 'content'),\n",
       " ('excitement', 'of', 'discovering', 'fabulous', 'content', 'across'),\n",
       " ('of', 'discovering', 'fabulous', 'content', 'across', 'OTT'),\n",
       " ('discovering', 'fabulous', 'content', 'across', 'OTT', 'platforms'),\n",
       " ('fabulous', 'content', 'across', 'OTT', 'platforms', 'with'),\n",
       " ('content', 'across', 'OTT', 'platforms', 'with', 'you'),\n",
       " ('across', 'OTT', 'platforms', 'with', 'you', '.'),\n",
       " ('OTT', 'platforms', 'with', 'you', '.', 'But'),\n",
       " ('platforms', 'with', 'you', '.', 'But', 'there'),\n",
       " ('with', 'you', '.', 'But', 'there', 'are'),\n",
       " ('you', '.', 'But', 'there', 'are', 'some'),\n",
       " ('.', 'But', 'there', 'are', 'some', 'who'),\n",
       " ('But', 'there', 'are', 'some', 'who', 'are'),\n",
       " ('there', 'are', 'some', 'who', 'are', 'simply'),\n",
       " ('are', 'some', 'who', 'are', 'simply', 'intimidated'),\n",
       " ('some', 'who', 'are', 'simply', 'intimidated', 'by'),\n",
       " ('who', 'are', 'simply', 'intimidated', 'by', 'the'),\n",
       " ('are', 'simply', 'intimidated', 'by', 'the', 'volume'),\n",
       " ('simply', 'intimidated', 'by', 'the', 'volume', 'of'),\n",
       " ('intimidated', 'by', 'the', 'volume', 'of', 'content'),\n",
       " ('by', 'the', 'volume', 'of', 'content', 'and'),\n",
       " ('the', 'volume', 'of', 'content', 'and', 'feel'),\n",
       " ('volume', 'of', 'content', 'and', 'feel', 'more'),\n",
       " ('of', 'content', 'and', 'feel', 'more', 'comfortable'),\n",
       " ('content', 'and', 'feel', 'more', 'comfortable', 'watching'),\n",
       " ('and', 'feel', 'more', 'comfortable', 'watching', 'reruns'),\n",
       " ('feel', 'more', 'comfortable', 'watching', 'reruns', 'on'),\n",
       " ('more', 'comfortable', 'watching', 'reruns', 'on', 'television'),\n",
       " ('comfortable', 'watching', 'reruns', 'on', 'television', '.'),\n",
       " ('watching', 'reruns', 'on', 'television', '.', 'The'),\n",
       " ('reruns', 'on', 'television', '.', 'The', 'free'),\n",
       " ('on', 'television', '.', 'The', 'free', 'forty'),\n",
       " ('television', '.', 'The', 'free', 'forty', 'eight'),\n",
       " ('.', 'The', 'free', 'forty', 'eight', 'hours'),\n",
       " ('The', 'free', 'forty', 'eight', 'hours', 'of'),\n",
       " ('free', 'forty', 'eight', 'hours', 'of', 'Netflix'),\n",
       " ('forty', 'eight', 'hours', 'of', 'Netflix', 'is'),\n",
       " ('eight', 'hours', 'of', 'Netflix', 'is', 'a'),\n",
       " ('hours', 'of', 'Netflix', 'is', 'a', 'great'),\n",
       " ('of', 'Netflix', 'is', 'a', 'great', 'opportunity'),\n",
       " ('Netflix', 'is', 'a', 'great', 'opportunity', 'for'),\n",
       " ('is', 'a', 'great', 'opportunity', 'for', 'those'),\n",
       " ('a', 'great', 'opportunity', 'for', 'those', 'still'),\n",
       " ('great', 'opportunity', 'for', 'those', 'still', 'wondering'),\n",
       " ('opportunity', 'for', 'those', 'still', 'wondering', 'what'),\n",
       " ('for', 'those', 'still', 'wondering', 'what', 'to'),\n",
       " ('those', 'still', 'wondering', 'what', 'to', 'watch'),\n",
       " ('still', 'wondering', 'what', 'to', 'watch', 'to'),\n",
       " ('wondering', 'what', 'to', 'watch', 'to', 'dive'),\n",
       " ('what', 'to', 'watch', 'to', 'dive', 'right'),\n",
       " ('to', 'watch', 'to', 'dive', 'right', 'in'),\n",
       " ('watch', 'to', 'dive', 'right', 'in', '.'),\n",
       " ('to', 'dive', 'right', 'in', '.', 'I'),\n",
       " ('dive', 'right', 'in', '.', 'I', '’'),\n",
       " ('right', 'in', '.', 'I', '’', 've'),\n",
       " ('in', '.', 'I', '’', 've', 'discovered'),\n",
       " ('.', 'I', '’', 've', 'discovered', 'a'),\n",
       " ('I', '’', 've', 'discovered', 'a', 'penchant'),\n",
       " ('’', 've', 'discovered', 'a', 'penchant', 'for'),\n",
       " ('ve', 'discovered', 'a', 'penchant', 'for', 'European'),\n",
       " ('discovered', 'a', 'penchant', 'for', 'European', 'shows'),\n",
       " ('a', 'penchant', 'for', 'European', 'shows', ','),\n",
       " ('penchant', 'for', 'European', 'shows', ',', 'shows'),\n",
       " ('for', 'European', 'shows', ',', 'shows', 'coming'),\n",
       " ('European', 'shows', ',', 'shows', 'coming', 'out'),\n",
       " ('shows', ',', 'shows', 'coming', 'out', 'of'),\n",
       " (',', 'shows', 'coming', 'out', 'of', 'Latin'),\n",
       " ('shows', 'coming', 'out', 'of', 'Latin', 'America'),\n",
       " ('coming', 'out', 'of', 'Latin', 'America', ','),\n",
       " ('out', 'of', 'Latin', 'America', ',', 'and'),\n",
       " ('of', 'Latin', 'America', ',', 'and', 'of'),\n",
       " ('Latin', 'America', ',', 'and', 'of', 'course'),\n",
       " ('America', ',', 'and', 'of', 'course', 'what'),\n",
       " (',', 'and', 'of', 'course', 'what', 'is'),\n",
       " ('and', 'of', 'course', 'what', 'is', 'known'),\n",
       " ('of', 'course', 'what', 'is', 'known', 'as'),\n",
       " ('course', 'what', 'is', 'known', 'as', 'K-Dramas'),\n",
       " ('what', 'is', 'known', 'as', 'K-Dramas', ','),\n",
       " ('is', 'known', 'as', 'K-Dramas', ',', 'Chinese'),\n",
       " ('known', 'as', 'K-Dramas', ',', 'Chinese', 'and'),\n",
       " ('as', 'K-Dramas', ',', 'Chinese', 'and', 'Japanese'),\n",
       " ('K-Dramas', ',', 'Chinese', 'and', 'Japanese', 'shows'),\n",
       " (',', 'Chinese', 'and', 'Japanese', 'shows', 'as'),\n",
       " ('Chinese', 'and', 'Japanese', 'shows', 'as', 'well'),\n",
       " ('and', 'Japanese', 'shows', 'as', 'well', '.'),\n",
       " ('Japanese', 'shows', 'as', 'well', '.', 'That'),\n",
       " ('shows', 'as', 'well', '.', 'That', '’'),\n",
       " ('as', 'well', '.', 'That', '’', 's'),\n",
       " ('well', '.', 'That', '’', 's', 'me'),\n",
       " ('.', 'That', '’', 's', 'me', ','),\n",
       " ('That', '’', 's', 'me', ',', 'and'),\n",
       " ('’', 's', 'me', ',', 'and', 'these'),\n",
       " ('s', 'me', ',', 'and', 'these', 'are'),\n",
       " ('me', ',', 'and', 'these', 'are', 'from'),\n",
       " (',', 'and', 'these', 'are', 'from', 'just'),\n",
       " ('and', 'these', 'are', 'from', 'just', 'one'),\n",
       " ('these', 'are', 'from', 'just', 'one', 'of'),\n",
       " ('are', 'from', 'just', 'one', 'of', 'the'),\n",
       " ('from', 'just', 'one', 'of', 'the', 'OTT'),\n",
       " ('just', 'one', 'of', 'the', 'OTT', 'platforms'),\n",
       " ('one', 'of', 'the', 'OTT', 'platforms', 'that'),\n",
       " ('of', 'the', 'OTT', 'platforms', 'that', 'is'),\n",
       " ('the', 'OTT', 'platforms', 'that', 'is', 'offering'),\n",
       " ('OTT', 'platforms', 'that', 'is', 'offering', 'us'),\n",
       " ('platforms', 'that', 'is', 'offering', 'us', 'all'),\n",
       " ('that', 'is', 'offering', 'us', 'all', 'a'),\n",
       " ('is', 'offering', 'us', 'all', 'a', 'break'),\n",
       " ('offering', 'us', 'all', 'a', 'break', 'from'),\n",
       " ('us', 'all', 'a', 'break', 'from', 'the'),\n",
       " ('all', 'a', 'break', 'from', 'the', 'monotony'),\n",
       " ('a', 'break', 'from', 'the', 'monotony', 'of'),\n",
       " ('break', 'from', 'the', 'monotony', 'of', 'being'),\n",
       " ('from', 'the', 'monotony', 'of', 'being', 'inside'),\n",
       " ('the', 'monotony', 'of', 'being', 'inside', 'and'),\n",
       " ('monotony', 'of', 'being', 'inside', 'and', 'safe'),\n",
       " ('of', 'being', 'inside', 'and', 'safe', 'from'),\n",
       " ('being', 'inside', 'and', 'safe', 'from', 'the'),\n",
       " ('inside', 'and', 'safe', 'from', 'the', 'pandemic'),\n",
       " ('and', 'safe', 'from', 'the', 'pandemic', 'taking'),\n",
       " ('safe', 'from', 'the', 'pandemic', 'taking', 'so'),\n",
       " ('from', 'the', 'pandemic', 'taking', 'so', 'many'),\n",
       " ('the', 'pandemic', 'taking', 'so', 'many', 'lives'),\n",
       " ('pandemic', 'taking', 'so', 'many', 'lives', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams\n",
    "a=list(bigrams(tokens))\n",
    "b=list(trigrams(tokens))\n",
    "v=list(ngrams(tokens,6))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28697011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
